{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======= ======= ======= **DEEP LEARNING E VISAO COMPUTACIONAL** ======= ======= =======\n",
    "** FACENET - Reconhecimento Facial com opencv-python, mtcnn**\n",
    "```\n",
    "Instalar pacotes pelo prompt do conda\n",
    "pandas\n",
    "opencv-python\n",
    "mtcnn\n",
    "PIL\n",
    "keras\n",
    "pickle\n",
    "numpy\n",
    "sklearn\n",
    "```\n",
    "**Identificar Versões Instaladas**\n",
    "```\n",
    "import cv2\n",
    "print('cv2 Version ',cv2.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** EXEMPLO PARA NOTEBOOK **\n",
    "\n",
    "** SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import os\n",
    "import subprocess\n",
    "from cv2 import *\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Classe \n",
    "class RegisterImg:\n",
    "    def __init__(self):\n",
    "        # Local Arquivo Que Armazenara Dados De Participante\n",
    "        self.arq_open = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        # Local Gravar Imagem Do Participante\n",
    "        self.grv_img = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        # Carregar Algoritmo Para \n",
    "        self.detector = MTCNN()\n",
    "        print(\"= SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder =\")\n",
    "\n",
    "    def face_mtcnn_extractor(self, frame):\n",
    "        \"\"\"Methods takes in frames from video, extracts and returns faces from them\"\"\"\n",
    "        # Use MTCNN to detect faces in each frame of the video\n",
    "        result = self.detector.detect_faces(frame)\n",
    "        return result\n",
    "    \n",
    "    def face_localizer(self, person):\n",
    "        \"\"\"Method takes the extracted faces and returns the coordinates\"\"\"\n",
    "        # 1. Get the coordinates of the face\n",
    "        bounding_box = person['box']\n",
    "        x1, y1 = abs(bounding_box[0]), abs(bounding_box[1])\n",
    "        width, height = bounding_box[2], bounding_box[3]\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        return x1, y1, x2, y2, width, height\n",
    "\n",
    "    def gravar_(self):\n",
    "        os.system('cls')\n",
    "        print(\"Gravando...\")\n",
    "        print(\"Digitar Dados Do Participante\")\n",
    "        matricula = 0\n",
    "        try:\n",
    "            matricula = int(input(\"Número Matrícula -> \"))\n",
    "        except ValueError:\n",
    "            print(\"\")\n",
    "            print(\"== Atenção ==\")\n",
    "            print(\"Digite Valor Númerico\")\n",
    "            print(\"              =======\")\n",
    "            menu = MainMenu()\n",
    "            menu.menu_inicial()\n",
    "\n",
    "        nome = input(\"Nome Completo -> \")\n",
    "        \n",
    "        # Gravar Imagem A partir Da Camera\n",
    "        # Inicializar Objeto Que Habilita Camera/WebCam Para Capturar Imagem. 0 = WebCam Notebook/PC\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        #Inicializar Objeto Para Detectar Uma Face Na Camera\n",
    "\n",
    "        while True:\n",
    "            # Detectar Face Em Cada Frame\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cam.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # 1. Extract faces from frames\n",
    "            result = self.face_mtcnn_extractor(frame)\n",
    "            #\n",
    "            k = cv2.waitKey(1)\n",
    "\n",
    "            # Desenhar Retângulo Na Face Detectada Utilizando As Coordenadas\n",
    "            for person in result:\n",
    "                # 2. Localize the face in the frame\n",
    "                x1, y1, x2, y2, width, height = self.face_localizer(person)\n",
    "\n",
    "                # 5. Draw a frame\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 155, 255), 2)\n",
    "\n",
    "            # display the frame with label\n",
    "            cv2.imshow(\"Coletar Imagens - ENTER = Gravar / ESC = Finalizar\", frame)\n",
    "\n",
    "            if k%256 == 27:\n",
    "                # Se pressionar o ESC\n",
    "                k = cv2.waitKey(2)\n",
    "                print(\"\")\n",
    "                print(\"ESC pressionado. Fechando Câmera\")\n",
    "                break\n",
    "            elif k%256 == 13: # Se pressionar o ENTER\n",
    "                # Converte a imagem para escala de cinza\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Criar Pasta Com Nome do Participante\n",
    "                os.mkdir(self.grv_img+\"train\\\\\"+nome+\"_\"+str(matricula))\n",
    "                os.mkdir(self.grv_img+\"test\\\\\"+nome+\"_\"+str(matricula))\n",
    "                # Persiste Imagem Em Disco\n",
    "                # Gravara Numero De Matrícula, Sequência Quantidade da Imagem Gravada\n",
    "                cv2.imwrite(self.grv_img+\"train\\\\\"+nome+\"_\"+str(matricula)+\"\\\\part-\"+str(matricula)+\".jpg\", gray[y1:y2,x1:x2])\n",
    "                cv2.imwrite(self.grv_img+\"test\\\\\"+nome+\"_\"+str(matricula)+\"\\\\part-\"+str(matricula)+\".jpg\", gray[y1:y2,x1:x2])\n",
    "\n",
    "                print(\"Imagem gravada!\")\n",
    "\n",
    "        # When everything's done, release capture\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import datetime\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from numpy import savez_compressed, asarray, load, expand_dims\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "class FaceTrainer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.datasetpath = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        self.faces_npz = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\faces_dataset.npz\"\n",
    "        self.keras_facenet = \"C:\\\\zprojeto-course\\\\deeplearn\\\\facenet\\\\facenet_keras.h5\"\n",
    "        self.faces_embeddings = \"C:\\\\zprojeto-course\\\\deeplearn\\\\facerecognition\\\\faces_dataset_embeddings.npz\"\n",
    "        self.svm_classifier = \"C:\\\\zprojeto-course\\\\deeplearn\\\\facerecognition\\\\SVM_classifier.sav\"\n",
    "        return\n",
    "\n",
    "    def load_dataset(self, directory):\n",
    "        \"\"\"Load a dataset that contains one subdir for each class that in turn contains images\"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "        # enumerate all folders named with class labels\n",
    "        for subdir in listdir(directory):\n",
    "            path = directory + subdir + '\\\\'\n",
    "            # skip any files that might be in the dir\n",
    "            if not isdir(path):\n",
    "                continue\n",
    "            # load all faces in the subdirectory\n",
    "            faces = self.load_faces(path)\n",
    "            # create labels\n",
    "            labels = [subdir for _ in range(len(faces))]\n",
    "            print(\"loaded {} examples for class: {}\".format(len(faces), subdir))\n",
    "            X.extend(faces)\n",
    "            y.extend(labels)\n",
    "        return asarray(X), asarray(y)\n",
    "\n",
    "    def load_faces(self, directory):\n",
    "        \"\"\"Load images and extract faces for all images in a directory\"\"\"\n",
    "        faces = []\n",
    "        # enumerate files\n",
    "        for filename in listdir(directory):\n",
    "            path = directory + filename\n",
    "            # get face\n",
    "            face = self.extract_face(path)\n",
    "            faces.append(face)\n",
    "        return faces\n",
    "\n",
    "    def extract_face(self, filename, required_size=(160, 160)):\n",
    "        \"\"\"Extract a single face from a given photograph\"\"\"\n",
    "        # load image from file\n",
    "        image = Image.open(filename)\n",
    "        # convert to RGB, if needed\n",
    "        image = image.convert('RGB')\n",
    "        # convert to array\n",
    "        pixels = asarray(image)\n",
    "        # create the detector, using default weights\n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        results = detector.detect_faces(pixels)\n",
    "        # extract the bounding box from the first face\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        # bug fix\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "\n",
    "    def create_faces_npz(self):\n",
    "        \"\"\"Method Creates npz file for all the faces in train_dir, val_dir\"\"\"\n",
    "        # Load the training data set\n",
    "        trainX, trainy = self.load_dataset(self.datasetpath+\"\\\\train\\\\\")\n",
    "        print(\"Training data set loaded\")\n",
    "        # load test dataset\n",
    "        testX, testy = self.load_dataset(self.datasetpath+\"\\\\test\\\\\")\n",
    "        print(\"Testing data set loaded\")\n",
    "        # save arrays to one file in compressed format\n",
    "        savez_compressed(self.faces_npz, trainX, trainy, testX, testy)\n",
    "        return\n",
    "\n",
    "    def create_faces_embedding_npz(self):\n",
    "        \"\"\"Create npz file for all the face embeddings in train_dir, val_dir\"\"\"\n",
    "        data = load(self.faces_npz)\n",
    "        trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "        print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "        # load the facenet model\n",
    "        model = load_model(self.keras_facenet)\n",
    "        print('Keras Facenet Model Loaded')\n",
    "        # convert each face in the train set to an embedding\n",
    "        newTrainX = list()\n",
    "        for face_pixels in trainX:\n",
    "            embedding = self.get_embedding(model, face_pixels)\n",
    "            newTrainX.append(embedding)\n",
    "        newTrainX = asarray(newTrainX)\n",
    "        # convert each face in the test set to an embedding\n",
    "        newTestX = list()\n",
    "        for face_pixels in testX:\n",
    "            embedding = self.get_embedding(model, face_pixels)\n",
    "            newTestX.append(embedding)\n",
    "        newTestX = asarray(newTestX)\n",
    "        # save arrays to one file in compressed format\n",
    "        savez_compressed(self.faces_embeddings, newTrainX, trainy, newTestX, testy)\n",
    "        return\n",
    "\n",
    "    def get_embedding(self, model, face_pixels):\n",
    "        \"\"\"Calculate a face embedding for each face in the dataset using facenet\n",
    "           Get the face embedding for one face\"\"\"\n",
    "        # scale pixel values\n",
    "        face_pixels = face_pixels.astype('float32')\n",
    "        # standardize pixel values across channels (global)\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        # transform face into one sample\n",
    "        samples = expand_dims(face_pixels, axis=0)\n",
    "        # make prediction to get embedding\n",
    "        yhat = model.predict(samples)\n",
    "        return yhat[0]\n",
    "\n",
    "    def classifier(self):\n",
    "        \"\"\"Create a Classifier for the Faces Dataset\"\"\"\n",
    "        # load dataset\n",
    "        data = load(self.faces_embeddings)\n",
    "        trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "        print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "        # normalize input vectors\n",
    "        in_encoder = Normalizer(norm='l2')\n",
    "        trainX = in_encoder.transform(trainX)\n",
    "        testX = in_encoder.transform(testX)\n",
    "        # label encode targets\n",
    "        out_encoder = LabelEncoder()\n",
    "        out_encoder.fit(trainy)\n",
    "        trainy = out_encoder.transform(trainy)\n",
    "        testy = out_encoder.transform(testy)\n",
    "        # fit model\n",
    "        model = SVC(kernel='linear', probability=True)\n",
    "        model.fit(trainX, trainy)\n",
    "        # save the model to disk\n",
    "        filename = self.svm_classifier\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        # predict\n",
    "        yhat_train = model.predict(trainX)\n",
    "        yhat_test = model.predict(testX)\n",
    "        # score\n",
    "        score_train = accuracy_score(trainy, yhat_train)\n",
    "        score_test = accuracy_score(testy, yhat_test)\n",
    "        # summarize\n",
    "        print('Accuracy: train=%.3f, test=%.3f' % (score_train * 100, score_test * 100))\n",
    "        return\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Method begins the training process\"\"\"\n",
    "        start_time = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"----------------------------------------------------------------------------------------\")\n",
    "        print(\"Face trainer Initiated at {}\".format(st))\n",
    "        print(\"----------------------------------------------------------------------------------------\")\n",
    "        # Get faces from the images\n",
    "        self.create_faces_npz()\n",
    "        # Get embeddings for all the extracted faces\n",
    "        self.create_faces_embedding_npz()\n",
    "        # Classify the faces\n",
    "        self.classifier()\n",
    "        end_time = time.time()\n",
    "        et = datetime.datetime.fromtimestamp(end_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"----------------------------------------------------------------------------------------\")\n",
    "        print(\"Face trainer Completed at {}\".format(et))\n",
    "        print(\"Total time Elapsed {} secs\".format(round(end_time - start_time), 0))\n",
    "        print(\"----------------------------------------------------------------------------------------\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "class FaceDetector:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.facenet_model = load_model(\"C:\\\\zprojeto-course\\\\deeplearn\\\\facenet\\\\facenet_keras.h5\")\n",
    "        self.svm_model = pickle.load(open(\"C:\\\\zprojeto-course\\\\deeplearn\\\\facerecognition\\\\SVM_classifier.sav\", 'rb'))\n",
    "        self.data = np.load('C:\\\\zprojeto-course\\\\deeplearn\\\\facerecognition\\\\faces_dataset_embeddings.npz')\n",
    "        # object to the MTCNN detector class\n",
    "        self.detector = MTCNN()\n",
    "\n",
    "    def face_mtcnn_extractor(self, frame):\n",
    "        \"\"\"Methods takes in frames from video, extracts and returns faces from them\"\"\"\n",
    "        # Use MTCNN to detect faces in each frame of the video\n",
    "        result = self.detector.detect_faces(frame)\n",
    "        return result\n",
    "\n",
    "    def face_localizer(self, person):\n",
    "        \"\"\"Method takes the extracted faces and returns the coordinates\"\"\"\n",
    "        # 1. Get the coordinates of the face\n",
    "        bounding_box = person['box']\n",
    "        x1, y1 = abs(bounding_box[0]), abs(bounding_box[1])\n",
    "        width, height = bounding_box[2], bounding_box[3]\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        return x1, y1, x2, y2, width, height\n",
    "\n",
    "    def face_preprocessor(self, frame, x1, y1, x2, y2, required_size=(160, 160)):\n",
    "        \"\"\"Method takes in frame, face coordinates and returns preprocessed image\"\"\"\n",
    "        # 1. extract the face pixels\n",
    "        face = frame[y1:y2, x1:x2]\n",
    "        # 2. resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = np.asarray(image)\n",
    "        # 3. scale pixel values\n",
    "        face_pixels = face_array.astype('float32')\n",
    "        # 4. standardize pixel values across channels (global)\n",
    "        mean, std = face_pixels.mean(), face_pixels.std()\n",
    "        face_pixels = (face_pixels - mean) / std\n",
    "        # 5. transform face into one sample\n",
    "        samples = np.expand_dims(face_pixels, axis=0)\n",
    "        # 6. get face embedding\n",
    "        yhat = self.facenet_model.predict(samples)\n",
    "        face_embedded = yhat[0]\n",
    "        # 7. normalize input vectors\n",
    "        in_encoder = Normalizer(norm='l2')\n",
    "        X = in_encoder.transform(face_embedded.reshape(1, -1))\n",
    "        return X\n",
    "\n",
    "    def face_svm_classifier(self, X):\n",
    "        \"\"\"Methods takes in preprocessed images ,classifies and returns predicted Class label and probability\"\"\"\n",
    "        # predict\n",
    "        yhat = self.svm_model.predict(X)\n",
    "        label = yhat[0]\n",
    "        yhat_prob = self.svm_model.predict_proba(X)\n",
    "        probability = round(yhat_prob[0][label], 2)\n",
    "        trainy = self.data['arr_1']\n",
    "        # predicted label decoder\n",
    "        out_encoder = LabelEncoder()\n",
    "        out_encoder.fit(trainy)\n",
    "        predicted_class_label = out_encoder.inverse_transform(yhat)\n",
    "        label = predicted_class_label[0]\n",
    "        return label, str(probability)\n",
    "\n",
    "    def face_detector(self):\n",
    "        \"\"\"Method classifies faces on live cam feed\n",
    "           Class labels : sai_ram, donald_trump,narendra_modi, virat_koli\"\"\"\n",
    "        # open cv for live cam feed\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            __, frame = cap.read()\n",
    "            # 1. Extract faces from frames\n",
    "            result = self.face_mtcnn_extractor(frame)\n",
    "            if result:\n",
    "                for person in result:\n",
    "                    # 2. Localize the face in the frame\n",
    "                    x1, y1, x2, y2, width, height = self.face_localizer(person)\n",
    "                    # 3. Proprocess the images for prediction\n",
    "                    X = self.face_preprocessor(frame, x1, y1, x2, y2, required_size=(160, 160))\n",
    "                    # 4. Predict class label and its probability\n",
    "                    label, probability = self.face_svm_classifier(X)\n",
    "                    print(\" Person : {} , Probability : {}\".format(label, probability))\n",
    "                    # 5. Draw a frame\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 155, 255), 2)\n",
    "                    # 6. Add the detected class label to the frame\n",
    "                    cv2.putText(frame, label+probability, (x1, height),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255),\n",
    "                                lineType=cv2.LINE_AA)\n",
    "            #\n",
    "            k = cv2.waitKey(1)\n",
    "            # display the frame with label\n",
    "            cv2.imshow(\"Identificando Imagem - ESC = Finalizar\", frame)\n",
    "            # break on keybord interuption with 'q'\n",
    "            if k%256 == 27:\n",
    "                # Se pressionar o ESC\n",
    "                k = cv2.waitKey(2)\n",
    "                print(\"\")\n",
    "                print(\"ESC pressionado. Fechando Câmera\")\n",
    "                break\n",
    "\n",
    "        # When everything's done, release capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas Para \n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Classe \n",
    "class MainMenu:\n",
    "    def __init__(self):\n",
    "        # Manipular Arquivo Que Armazenara Dados De Participante\n",
    "        self.arq_open = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        # Nome Do Arquivo que armazenara Dados De Participante\n",
    "        self.arq_nome = \"labelmap.csv\"\n",
    "        # Gravar Imagem Do Participante\n",
    "        self.grv_img = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        self.detector = MTCNN()\n",
    "        print(\"= SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder =\")\n",
    "\n",
    "    def menu_inicial(self):\n",
    "        print(\"\")\n",
    "        print(\"Digite O Número Relacionado a Opção Desejada\")\n",
    "        print(\"\")\n",
    "        print(\"1 Gravar Imagem\")\n",
    "        print(\"2 Analisar Imagem\")\n",
    "        print(\"3 Identificar Imagem\")\n",
    "        print(\"0 Sair Do Sistema\")\n",
    "        choice = 0\n",
    "        try:\n",
    "            choice = int(input(\" >> \"))\n",
    "        except ValueError:\n",
    "            print(\"\")\n",
    "            print(\"== Atenção ==\")\n",
    "            print(\"Digite Valor Númerico\")\n",
    "            print(\"             =======\")\n",
    "            self.menu_inicial()\n",
    "\n",
    "        self.choice = choice\n",
    "        self.chama_acoes(str(self.choice))\n",
    "\n",
    "    def face_mtcnn_extractor(self, frame):\n",
    "        \"\"\"Methods takes in frames from video, extracts and returns faces from them\"\"\"\n",
    "        # Use MTCNN to detect faces in each frame of the video\n",
    "        result = self.detector.detect_faces(frame)\n",
    "        return result\n",
    "    \n",
    "    def face_localizer(self, person):\n",
    "        \"\"\"Method takes the extracted faces and returns the coordinates\"\"\"\n",
    "        # 1. Get the coordinates of the face\n",
    "        bounding_box = person['box']\n",
    "        x1, y1 = abs(bounding_box[0]), abs(bounding_box[1])\n",
    "        width, height = bounding_box[2], bounding_box[3]\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        return x1, y1, x2, y2, width, height\n",
    "\n",
    "    def gravar_(self):\n",
    "        os.system('cls')\n",
    "        print(\"Gravando...\")\n",
    "        print(\"Digitar Dados Do Participante\")\n",
    "        gravar = RegisterImg()\n",
    "        gravar.gravar_()\n",
    "\n",
    "        os.system('cls')\n",
    "        self.menu_inicial()\n",
    "        return\n",
    "\n",
    "    def analisar_(self):\n",
    "        print(\"Analisando Imagem ...\")\n",
    "        analisar = FaceTrainer()\n",
    "        analisar.start()\n",
    "        os.system('cls')\n",
    "        self.menu_inicial()\n",
    "        return\n",
    "\n",
    "    def identificar_(self):\n",
    "        print(\"Identificando Imagem ...\")\n",
    "        identificar = FaceDetector()\n",
    "        identificar.face_detector()\n",
    "        os.system('cls')\n",
    "        self.menu_inicial()\n",
    "        return\n",
    "\n",
    "    def sair_(self):\n",
    "        print(\"Sistema Encerrado !\")\n",
    "        os.system('cls')\n",
    "        quit()\n",
    "        return\n",
    "\n",
    "    def chama_acoes(self,ch):\n",
    "        self.menu_acoes(ch)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def menu_acoes(self,opcao):\n",
    "        menu_actions = {\n",
    "                        'main_menu': self.menu_inicial,\n",
    "                        '1': self.gravar_,\n",
    "                        '2': self.analisar_,\n",
    "                        '3': self.identificar_,\n",
    "                        '0': self.sair_\n",
    "                        }\n",
    "        menu_actions[opcao]()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder =\n",
      "\n",
      "Digite O Número Relacionado a Opção Desejada\n",
      "\n",
      "1 Gravar Imagem\n",
      "2 Analisar Imagem\n",
      "3 Identificar Imagem\n",
      "0 Sair Do Sistema\n",
      " >> 1\n",
      "Gravando...\n",
      "Digitar Dados Do Participante\n",
      "= SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder =\n",
      "Gravando...\n",
      "Digitar Dados Do Participante\n",
      "Número Matrícula -> 1\n",
      "Nome Completo -> Carlos Leite\n",
      "Imagem gravada!\n",
      "\n",
      "ESC pressionado. Fechando Câmera\n",
      "\n",
      "Digite O Número Relacionado a Opção Desejada\n",
      "\n",
      "1 Gravar Imagem\n",
      "2 Analisar Imagem\n",
      "3 Identificar Imagem\n",
      "0 Sair Do Sistema\n",
      " >> 2\n",
      "Analisando Imagem ...\n",
      "----------------------------------------------------------------------------------------\n",
      "Face trainer Initiated at 2020-07-02 23:35:40\n",
      "----------------------------------------------------------------------------------------\n",
      "loaded 1 examples for class: Aaron_Peirsol\n",
      "loaded 1 examples for class: Aaron_Sorkin\n",
      "loaded 1 examples for class: Abdel_Nasser_Assidi\n",
      "loaded 1 examples for class: Abdoulaye_Wade\n",
      "loaded 1 examples for class: Abdullah\n",
      "loaded 1 examples for class: Abdullah_al-Attiyah\n",
      "loaded 1 examples for class: Abdullah_Gul\n",
      "loaded 1 examples for class: Abdullatif_Sener\n",
      "loaded 1 examples for class: Abel_Pacheco\n",
      "loaded 1 examples for class: Abid_Hamid_Mahmud_Al-Tikriti\n",
      "loaded 1 examples for class: Adam_Sandler\n",
      "loaded 1 examples for class: Adam_Scott\n",
      "loaded 1 examples for class: Adel_Al-Jubeir\n",
      "loaded 1 examples for class: Adolfo_Aguilar_Zinser\n",
      "loaded 1 examples for class: Adolfo_Rodriguez_Saa\n",
      "loaded 1 examples for class: Adrian_McPherson\n",
      "loaded 1 examples for class: Adrian_Nastase\n",
      "loaded 1 examples for class: Adrien_Brody\n",
      "loaded 1 examples for class: Ahmad_Masood\n",
      "loaded 1 examples for class: Ahmed_Chalabi\n",
      "loaded 1 examples for class: Ahmet_Necdet_Sezer\n",
      "loaded 1 examples for class: Aicha_El_Ouafi\n",
      "loaded 1 examples for class: Aitor_Gonzalez\n",
      "loaded 1 examples for class: Ai_Sugiyama\n",
      "loaded 1 examples for class: Angelina_julie\n",
      "loaded 1 examples for class: Carlos Leite_1\n",
      "loaded 1 examples for class: Michael_Jackson\n",
      "loaded 1 examples for class: Rihanna_ri\n",
      "loaded 1 examples for class: Shakira_sha\n",
      "Training data set loaded\n",
      "loaded 2 examples for class: Aaron_Peirsol\n",
      "loaded 2 examples for class: Aaron_Sorkin\n",
      "loaded 2 examples for class: Abdel_Nasser_Assidi\n",
      "loaded 3 examples for class: Abdoulaye_Wade\n",
      "loaded 2 examples for class: Abdullah\n",
      "loaded 2 examples for class: Abdullah_al-Attiyah\n",
      "loaded 2 examples for class: Abdullah_Gul\n",
      "loaded 2 examples for class: Abdullatif_Sener\n",
      "loaded 2 examples for class: Abel_Pacheco\n",
      "loaded 2 examples for class: Abid_Hamid_Mahmud_Al-Tikriti\n",
      "loaded 2 examples for class: Adam_Sandler\n",
      "loaded 2 examples for class: Adam_Scott\n",
      "loaded 2 examples for class: Adel_Al-Jubeir\n",
      "loaded 2 examples for class: Adolfo_Aguilar_Zinser\n",
      "loaded 2 examples for class: Adolfo_Rodriguez_Saa\n",
      "loaded 2 examples for class: Adrian_McPherson\n",
      "loaded 2 examples for class: Adrian_Nastase\n",
      "loaded 2 examples for class: Adrien_Brody\n",
      "loaded 2 examples for class: Ahmad_Masood\n",
      "loaded 2 examples for class: Ahmed_Chalabi\n",
      "loaded 2 examples for class: Ahmet_Necdet_Sezer\n",
      "loaded 2 examples for class: Aicha_El_Ouafi\n",
      "loaded 2 examples for class: Aitor_Gonzalez\n",
      "loaded 2 examples for class: Ai_Sugiyama\n",
      "loaded 4 examples for class: Angelina_julie\n",
      "loaded 1 examples for class: Carlos Leite_1\n",
      "loaded 3 examples for class: Michael_Jackson\n",
      "loaded 3 examples for class: Rihanna_ri\n",
      "loaded 3 examples for class: Shakira_sha\n",
      "Testing data set loaded\n",
      "Loaded:  (29, 160, 160, 3) (29,) (63, 160, 160, 3) (63,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\zprogramas\\jupyter\\Miniconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Facenet Model Loaded\n",
      "Dataset: train=29, test=63\n",
      "Accuracy: train=100.000, test=95.238\n",
      "----------------------------------------------------------------------------------------\n",
      "Face trainer Completed at 2020-07-02 23:38:12\n",
      "Total time Elapsed 152 secs\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "Digite O Número Relacionado a Opção Desejada\n",
      "\n",
      "1 Gravar Imagem\n",
      "2 Analisar Imagem\n",
      "3 Identificar Imagem\n",
      "0 Sair Do Sistema\n",
      " >> 3\n",
      "Identificando Imagem ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\zprogramas\\jupyter\\Miniconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.03\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      " Person : Carlos Leite_1 , Probability : 0.02\n",
      "\n",
      "ESC pressionado. Fechando Câmera\n",
      "\n",
      "Digite O Número Relacionado a Opção Desejada\n",
      "\n",
      "1 Gravar Imagem\n",
      "2 Analisar Imagem\n",
      "3 Identificar Imagem\n",
      "0 Sair Do Sistema\n",
      " >> 0\n",
      "Sistema Encerrado !\n"
     ]
    }
   ],
   "source": [
    "# Chama Classe MainMenu Para Exibir Menu Que Será Manipulado\n",
    "if __name__ == \"__main__\":\n",
    "    os.system('cls')\n",
    "    menu = MainMenu()\n",
    "    menu.menu_inicial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from cv2 import *\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# Classe \n",
    "class RegisterImg:\n",
    "    def __init__(self):\n",
    "        # Local Arquivo Que Armazenara Dados De Participante\n",
    "        self.arq_open = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        # Local Gravar Imagem Do Participante\n",
    "        self.grv_img = \"C:\\\\zprojeto-course\\\\deeplearn\\\\dataset\\\\\"\n",
    "        # Carregar Algoritmo Para \n",
    "        self.detector = MTCNN()\n",
    "        print(\"= SISTEMA RECONHECIMENTO FACIAL ATRAVÉS DE CAMERA - OpenVC, MTCNN, LabelEncoder =\")\n",
    "\n",
    "    def face_mtcnn_extractor(self, frame):\n",
    "        \"\"\"Methods takes in frames from video, extracts and returns faces from them\"\"\"\n",
    "        # Use MTCNN to detect faces in each frame of the video\n",
    "        result = self.detector.detect_faces(frame)\n",
    "        return result\n",
    "    \n",
    "    def face_localizer(self, person):\n",
    "        \"\"\"Method takes the extracted faces and returns the coordinates\"\"\"\n",
    "        # 1. Get the coordinates of the face\n",
    "        bounding_box = person['box']\n",
    "        x1, y1 = abs(bounding_box[0]), abs(bounding_box[1])\n",
    "        width, height = bounding_box[2], bounding_box[3]\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        return x1, y1, x2, y2, width, height\n",
    "\n",
    "    def gravar_(self):\n",
    "        os.system('cls')\n",
    "        print(\"Gravando...\")\n",
    "        print(\"Digitar Dados Do Participante\")\n",
    "        matricula = 0\n",
    "        try:\n",
    "            matricula = int(input(\"Número Matrícula -> \"))\n",
    "        except ValueError:\n",
    "            print(\"\")\n",
    "            print(\"== Atenção ==\")\n",
    "            print(\"Digite Valor Númerico\")\n",
    "            print(\"              =======\")\n",
    "            menu = MainMenu()\n",
    "            menu.menu_inicial()\n",
    "\n",
    "        nome = input(\"Nome Completo -> \")\n",
    "        \n",
    "        # Gravar Imagem A partir Da Camera\n",
    "        # Inicializar Objeto Que Habilita Camera/WebCam Para Capturar Imagem. 0 = WebCam Notebook/PC\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        #Inicializar Objeto Para Detectar Uma Face Na Camera\n",
    "\n",
    "        while True:\n",
    "            # Detectar Face Em Cada Frame\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cam.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # 1. Extract faces from frames\n",
    "            result = self.face_mtcnn_extractor(frame)\n",
    "            #\n",
    "            k = cv2.waitKey(1)\n",
    "\n",
    "            # Desenhar Retângulo Na Face Detectada Utilizando As Coordenadas\n",
    "            for person in result:\n",
    "                # 2. Localize the face in the frame\n",
    "                x1, y1, x2, y2, width, height = self.face_localizer(person)\n",
    "\n",
    "                # 5. Draw a frame\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 155, 255), 2)\n",
    "\n",
    "            # display the frame with label\n",
    "            cv2.imshow(\"Coletar Imagens - ENTER = Gravar / ESC = Finalizar\", frame)\n",
    "\n",
    "            if k%256 == 27:\n",
    "                # Se pressionar o ESC\n",
    "                k = cv2.waitKey(2)\n",
    "                print(\"\")\n",
    "                print(\"ESC pressionado. Fechando Câmera\")\n",
    "                break\n",
    "            elif k%256 == 13: # Se pressionar o ENTER\n",
    "                # Converte a imagem para escala de cinza\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Criar Pasta Com Nome do Participante\n",
    "                os.mkdir(self.grv_img+\"train\\\\\"+nome+\"_\"+str(matricula))\n",
    "                os.mkdir(self.grv_img+\"test\\\\\"+nome+\"_\"+str(matricula))\n",
    "                # Persiste Imagem Em Disco\n",
    "                # Gravara Numero De Matrícula, Sequência Quantidade da Imagem Gravada\n",
    "                cv2.imwrite(self.grv_img+\"train\\\\\"+nome+\"_\"+str(matricula)+\"\\\\part-\"+str(matricula)+\".jpg\", gray[y1:y2,x1:x2])\n",
    "                cv2.imwrite(self.grv_img+\"test\\\\\"+nome+\"_\"+str(matricula)+\"\\\\part-\"+str(matricula)+\".jpg\", gray[y1:y2,x1:x2])\n",
    "\n",
    "                print(\"Imagem gravada!\")\n",
    "\n",
    "        # When everything's done, release capture\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
